# -*- coding: utf-8 -*-
"""brown corpus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SUsk825Vg3XodErL7MRvwjcMyODaeR99
"""

import nltk

nltk.download('brown')

nltk.download('wordnet')

import nltk

brown = nltk.corpus.brown

words_and_categories = []
for word, tag in brown.tagged_words():
    words_and_categories.append((word, tag))

words_with_parts_of_speech = {}

for word, tag in words_and_categories:
    if word in ["ab","run", "look", "set", "air","absent", "abbatical","ABATE","abate","abacus","school"]:
        if word in words_with_parts_of_speech:
            words_with_parts_of_speech[word].add(tag)
        else:
            words_with_parts_of_speech[word] = set([tag])

for word, tags in words_with_parts_of_speech.items():
    print(f"{word}: {', '.join(tags)}")

import nltk
import json

nltk.download('brown')

brown = nltk.corpus.brown

desired_tags = ['NN', 'NNS', 'NN$', 'NN-TL', 'NNS-TL', 'NP', 'NPS', 'NP$', 'VB', 'VBG', 'VB$', 'VBD', 'VBN', 'VBZ',
                'JJ', 'JJ$', 'JJR', 'JJS', 'RB', 'RBR', 'RBT', 'RN', 'RP', 'IN', 'CC', 'UH']

with open('words2.json', 'r') as file:
    data = json.load(file)
    words_to_check = data["words"]
    print("Words to check:", words_to_check)

words_with_parts_of_speech = {}

for word, tag in brown.tagged_words():
    if word in words_to_check and tag in desired_tags:
        if word in words_with_parts_of_speech:
            words_with_parts_of_speech[word].add(tag)
        else:
            words_with_parts_of_speech[word] = set([tag])

pos_labels = {
    'NN': 'Noun',
    'NNS': 'Noun',
    'NN$': 'Noun',
    'NN-TL': 'Noun',
    'NNS-TL': 'Noun',
    'NP': 'Noun',
    'NPS': 'Noun',
    'NP$': 'Noun',
    'VB': 'Verb',
    'VBG': 'Verb',
    'VB$': 'Verb',
    'VBD': 'Verb',
    'VBN': 'Verb',
    'VBZ': 'Verb',
    'JJ': 'Adjective',
    'JJ$': 'Adjective',
    'JJR': 'Adjective',
    'JJS': 'Adjective',
    'RB': 'Adverb',
    'RBR': 'Adverb',
    'RBT': 'Adverb',
    'RN': 'Adverb',
    'RP': 'Adverb',
    'IN': 'Preposition',
    'CC': 'Conjunction',
    'UH': 'Interjection'
}

for word, tags in words_with_parts_of_speech.items():
    pos_labels_list = [pos_labels[tag] for tag in tags]
    print(f"{word}: {', '.join(pos_labels_list)} ({', '.join(tags)})")

import nltk
import json

nltk.download('brown')

brown = nltk.corpus.brown

desired_tags = ['NN', 'NNS', 'NN$', 'NN-TL', 'NNS-TL', 'NP', 'NPS', 'NP$', 'VB', 'VBG', 'VB$', 'VBD', 'VBN', 'VBZ',
                'JJ', 'JJ$', 'JJR', 'JJS', 'RB', 'RBR', 'RBT', 'RN', 'RP', 'IN', 'CC', 'UH']

with open('words2.json', 'r') as file:
    data = json.load(file)
    words_to_check = data["words"]
    print("Words to check:", words_to_check)

words_to_check_lower = [word.lower() for word in words_to_check]

words_with_parts_of_speech = {}

for word, tag in brown.tagged_words():
    word = word.lower()

    if word in words_to_check_lower and tag in desired_tags:
        original_word = words_to_check[words_to_check_lower.index(word)]
        if original_word in words_with_parts_of_speech:
            words_with_parts_of_speech[original_word].add(tag)
        else:
            words_with_parts_of_speech[original_word] = set([tag])

pos_labels = {
    'NN': 'Noun',
    'NNS': 'Noun',
    'NN$': 'Noun',
    'NN-TL': 'Noun',
    'NNS-TL': 'Noun',
    'NP': 'Noun',
    'NPS': 'Noun',
    'NP$': 'Noun',
    'VB': 'Verb',
    'VBG': 'Verb',
    'VB$': 'Verb',
    'VBD': 'Verb',
    'VBN': 'Verb',
    'VBZ': 'Verb',
    'JJ': 'Adjective',
    'JJ$': 'Adjective',
    'JJR': 'Adjective',
    'JJS': 'Adjective',
    'RB': 'Adverb',
    'RBR': 'Adverb',
    'RBT': 'Adverb',
    'RN': 'Adverb',
    'RP': 'Adverb',
    'IN': 'Preposition',
    'CC': 'Conjunction',
    'UH': 'Interjection'
}

for word, tags in words_with_parts_of_speech.items():
    pos_labels_list = [pos_labels[tag] for tag in tags]
    print(f"{word}: {', '.join(pos_labels_list)}")

